{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library functions\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "import multiprocessing\n",
    "from numpy import round\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "# from sklearnex import patch_sklearn\n",
    "\n",
    "# Our functions\n",
    "from utils import TextPreprocessor, FeatureGenerator, remove_nan_questions, get_param_grid\n",
    "\n",
    "# patch_sklearn()  # to speed up scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_path_folder_quora = \"~/Datasets/QuoraQuestionPairs\"\n",
    "MODELS_DIR = \"model_artifacts\"\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "    print(f\"Folder '{MODELS_DIR}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{MODELS_DIR}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_df = pd.read_csv(\"C:/Users/polri/Desktop/NLP/Assignment1/FlaviaFerrus_PolRiba_GerardCastro_ClaudiaHerron/QuoraQuestionPairs/Datasets/quora_train_data.csv\")\n",
    "x_train = _train_df.loc[:, [\"question1\", \"question2\"]]\n",
    "y_train = _train_df.loc[:, \"is_duplicate\"]\n",
    "\n",
    "x_train, y_train = remove_nan_questions(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_train, y_train, test_size=0.2, random_state=SEED)\n",
    "# and we fit the pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SEARCH: bool = False  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GRID_SEARCH:\n",
    "    models = {\"AdaBoostClassifier\": AdaBoostClassifier(n_estimators=20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GRID_SEARCH:\n",
    "    pipe = Pipeline(\n",
    "            [('preprocessor', TextPreprocessor()),\n",
    "             ('generator', FeatureGenerator(exts=('cv_2w', 'tf_idf_2w'), aggs=('stack', 'absolute'))),\n",
    "             ('classifier', models[\"AdaBoostClassifier\"])],\n",
    "            verbose=True)\n",
    "    pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRID_SEARCH:\n",
    "    models = {\n",
    "        \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "        \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "        \"LinearDiscriminantAnalysis\": LinearDiscriminantAnalysis(),\n",
    "        \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "        \"BernoulliNB\": BernoulliNB(),\n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "        \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "        \"SVC\": SVC(),\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "        \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "        \"XGBClassifier\": XGBClassifier(n_jobs=multiprocessing.cpu_count() - 1),\n",
    "        \"CatBoostClassifier\": CatBoostClassifier(silent=True\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRID_SEARCH:\n",
    "    fitted_models = {}\n",
    "    scores = {}\n",
    "    for name, model in tqdm(models.items()):\n",
    "        # define pipeline given a model\n",
    "        pipe = Pipeline(\n",
    "            [('preprocessor', TextPreprocessor()),\n",
    "             ('generator', FeatureGenerator(exts=('cv_2w', 'tf_idf_2w'), aggs=('stack', 'absolute'))),\n",
    "             ('classifier', model)],\n",
    "            verbose=True)\n",
    "        # get grid of parameters to search\n",
    "        grid = get_param_grid(name, SEED)\n",
    "        grid = {}\n",
    "        grid_search = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid=grid,\n",
    "            scoring= \"roc_auc\",\n",
    "            cv=2,\n",
    "            verbose=10,\n",
    "            n_jobs=multiprocessing.cpu_count() - 1,\n",
    "            error_score=\"raise\",\n",
    "        )\n",
    "\n",
    "        # fit grid search with pipeline and grid\n",
    "        grid_search.fit(x_train, y_train)\n",
    "\n",
    "        # save model\n",
    "        fitted_models[name] = grid_search.best_estimator_\n",
    "        scores[name] = grid_search.best_score_\n",
    "\n",
    "        joblib.dump(grid_search, os.path.join(MODELS_DIR, f\"fitted_{name}.pk1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRID_SEARCH:\n",
    "    best_model_name = max(scores)\n",
    "    best_model = fitted_models[best_model_name]\n",
    "    print(f\"Best model found in the grid search is {best_model_name}, with a CV score of {scores[best_model_name]:.4f}\")\n",
    "    fitted_pipe = best_model\n",
    "else:\n",
    "    fitted_pipe = pipe\n",
    "    \n",
    "joblib.dump(fitted_pipe, f'{MODELS_DIR}/fitted_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = fitted_pipe.predict(x_train)\n",
    "y_pred_test = fitted_pipe.predict(x_test)\n",
    "\n",
    "fpr_train, tpr_train, _ = roc_curve(\n",
    "    y_train, fitted_pipe.predict_log_proba(x_train)[:, 1])\n",
    "auc_roc_train = auc(fpr_train, tpr_train)\n",
    "fpr_test, tpr_test, _ = roc_curve(\n",
    "    y_test, fitted_pipe.predict_log_proba(x_test)[:, 1])\n",
    "auc_roc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "print(\"TRAINING results:\\n\", classification_report(y_train, y_pred_train))\n",
    "print(\"TESTING results:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"Training AUC:\", auc_roc_train)\n",
    "print(\"Testing AUC:\", auc_roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_train, tpr_train,\n",
    "         label=f'Train (AUC = {round(auc_roc_train, 3)})')\n",
    "plt.plot(fpr_test, tpr_test,\n",
    "         label=f'Test (AUC = {round(auc_roc_test, 3)})')\n",
    "plt.legend()\n",
    "plt.savefig(f'{MODELS_DIR}/fitted_pipe_roc.png', dpi=250)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
