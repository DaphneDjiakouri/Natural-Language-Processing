{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library functions\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from xgboost import XGBClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "import multiprocessing\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Our functions\n",
    "from utils import TextPreprocessor, FeatureGenerator, remove_nan_questions, get_param_grid\n",
    "# patch_sklearn()  # to speed up scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_path_folder_quora = \"~/Datasets/QuoraQuestionPairs\"\n",
    "MODELS_DIR = \"model_artifacts\"\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "    print(f\"Folder '{MODELS_DIR}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{MODELS_DIR}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(_path_folder_quora, \"quora_train_data.csv\"))\n",
    "x_train = train_df.loc[:, [\"question1\", \"question2\"]]\n",
    "y_train = train_df.loc[:, \"is_duplicate\"]\n",
    "\n",
    "x_train, y_train = remove_nan_questions(x_train, y_train)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_train, y_train, test_size=0.05, random_state=SEED)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(\n",
    "        x_train, y_train, test_size=0.05, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "            [('preprocessor', TextPreprocessor(\n",
    "                to_lower=True\n",
    "            )),\n",
    "             ('generator', FeatureGenerator(exts=('cv', ), aggs=('stack', ), extra_features=tuple())),\n",
    "             ('classifier', LogisticRegression(max_iter=1000, solver=\"liblinear\",random_state=SEED))],\n",
    "            verbose=True)\n",
    "\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe, os.path.join(MODELS_DIR, f\"simple_solution.pk1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SEARCH: bool = False  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRID_SEARCH:\n",
    "    models = {\n",
    "            \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "            \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "            \"LinearDiscriminantAnalysis\": LinearDiscriminantAnalysis(),\n",
    "            \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "            \"BernoulliNB\": BernoulliNB(),\n",
    "            \"GaussianNB\": GaussianNB(),\n",
    "            \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "            \"SVC\": SVC(),\n",
    "            \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state = SEED),\n",
    "            \"GradientBoostingClassifier\": GradientBoostingClassifier()\n",
    "            #\"XGBClassifier\": XGBClassifier(n_jobs=multiprocessing.cpu_count() - 1),\n",
    "            #\"CatBoostClassifier\": CatBoostClassifier(silent=True),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GRID_SEARCH:\n",
    "    models = {\"LogisticRegression\": LogisticRegression(max_iter=1000, random_state = SEED)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GRID_SEARCH:\n",
    "    pipe = Pipeline(\n",
    "            [('preprocessor', # TextPreprocessor()\n",
    "              TextPreprocessor(\n",
    "                 remove_stop_words = True,\n",
    "                 remove_punctuation = True,\n",
    "                 to_lower = True,\n",
    "                 apply_stemming = True,\n",
    "                 british = False)\n",
    "            ),\n",
    "             ('generator', FeatureGenerator(exts=('cv_2w', 'tf_idf_2w'), aggs=('stack', 'absolute'))),\n",
    "             ('classifier', models['LogisticRegression'])],\n",
    "            verbose=True)\n",
    "    pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GRID_SEARCH:\n",
    "    joblib.dump(pipe, f'{MODELS_DIR}/improved_solution.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRID_SEARCH:\n",
    "    fitted_models = {}\n",
    "    scores = {}\n",
    "    for name, model in tqdm(models.items()):\n",
    "        # define pipeline given a model\n",
    "        pipe = Pipeline(\n",
    "            [('preprocessor', TextPreprocessor()),\n",
    "             ('generator', FeatureGenerator()),\n",
    "             ('classifier', model)],\n",
    "            verbose=True)\n",
    "        # get grid of parameters to search\n",
    "        grid = get_param_grid(name, SEED)\n",
    "        grid_search = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid=grid,\n",
    "            scoring= \"roc_auc\",\n",
    "            cv=2,\n",
    "            verbose=10,\n",
    "            n_jobs=multiprocessing.cpu_count() - 1,\n",
    "            error_score=\"raise\",\n",
    "        )\n",
    "\n",
    "        # fit grid search with pipeline and grid\n",
    "        grid_search.fit(x_train, y_train)\n",
    "\n",
    "        # save model\n",
    "        fitted_models[name] = grid_search.best_estimator_\n",
    "        scores[name] = grid_search.best_score_\n",
    "\n",
    "        joblib.dump(grid_search, os.path.join(MODELS_DIR, f\"fitted_{name}.pk1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRID_SEARCH:\n",
    "    best_model_name = max(scores)\n",
    "    best_model = fitted_models[best_model_name]\n",
    "    print(f\"Best model found in the grid search is {best_model_name}, with a CV score of {scores[best_model_name]:.4f}\")\n",
    "    fitted_pipe = best_model\n",
    "    joblib.dump(fitted_pipe, f'{MODELS_DIR}/improved_solution.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
